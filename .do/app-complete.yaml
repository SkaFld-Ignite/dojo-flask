name: ai-video-chaptering-complete
region: nyc

# Databases - Managed by DigitalOcean
databases:
  - name: postgres-db
    engine: PG
    production: true
    cluster_name: video-chaptering-db
    version: "15"
    size: db-s-1vcpu-1gb
    num_nodes: 1

  - name: redis-db
    engine: REDIS
    production: true
    cluster_name: video-chaptering-redis
    version: "7"
    size: db-s-1vcpu-1gb
    num_nodes: 1

# Services
services:
  # Backend API Service
  - name: backend-api
    source_dir: /
    github:
      repo: mikebelloli/dojo-flask
      branch: main
      deploy_on_push: true
    dockerfile_path: Dockerfile
    build_command: |
      echo "Building Flask backend with AI capabilities..."
    run_command: |
      python -m flask db upgrade
      gunicorn --bind 0.0.0.0:8080 --workers 2 --worker-class eventlet --timeout 300 --keep-alive 2 --max-requests 1000 --max-requests-jitter 100 "backend.src:create_app()"
    environment_slug: python
    instance_count: 1
    instance_size_slug: basic-xs
    http_port: 8080
    routes:
      - path: /api
      - path: /socket.io
    health_check:
      http_path: /api/health
      initial_delay_seconds: 60
      period_seconds: 10
      timeout_seconds: 5
      success_threshold: 1
      failure_threshold: 3
    envs:
      # Core Flask Configuration
      - key: FLASK_ENV
        value: production
      - key: DATABASE_URL
        value: ${postgres-db.DATABASE_URL}
      - key: REDIS_URL
        value: ${redis-db.DATABASE_URL}
      - key: SECRET_KEY
        value: ${SECRET_KEY}
        type: SECRET
      
      # CORS for frontend integration
      - key: CORS_ORIGINS
        value: https://${frontend.DOMAIN},https://${_self.DOMAIN}
      
      # File Storage Paths
      - key: MODEL_CACHE_DIR
        value: /app/models
      - key: UPLOAD_FOLDER
        value: /app/storage/uploads
      - key: PROCESSED_FOLDER
        value: /app/storage/processed
      - key: MAX_CONTENT_LENGTH
        value: 500MB
      
      # AI Model Configuration
      - key: WHISPER_MODEL
        value: base
      - key: LLM_MODEL
        value: microsoft/DialoGPT-medium
      - key: USE_GPU
        value: "false"
      - key: DEVICE
        value: cpu
      
      # DigitalOcean Spaces Configuration
      - key: DO_SPACES_ENDPOINT
        value: ${DO_SPACES_ENDPOINT}
        type: SECRET
      - key: DO_SPACES_BUCKET
        value: ${DO_SPACES_BUCKET}
        type: SECRET
      - key: DO_SPACES_ACCESS_KEY
        value: ${DO_SPACES_ACCESS_KEY}
        type: SECRET
      - key: DO_SPACES_SECRET_KEY
        value: ${DO_SPACES_SECRET_KEY}
        type: SECRET
      - key: DO_SPACES_REGION
        value: nyc3
      
      # Celery Configuration
      - key: CELERY_BROKER_URL
        value: ${redis-db.DATABASE_URL}
      - key: CELERY_RESULT_BACKEND
        value: ${redis-db.DATABASE_URL}
      
      # WebSocket Configuration
      - key: SOCKETIO_ASYNC_MODE
        value: eventlet
      - key: SOCKETIO_CORS_ALLOWED_ORIGINS
        value: https://${frontend.DOMAIN}
      
      # Logging and Monitoring
      - key: LOG_LEVEL
        value: INFO
      - key: LOG_FILE
        value: /app/logs/app.log
      - key: SENTRY_DSN
        value: ${SENTRY_DSN}
        type: SECRET
      
      # Security
      - key: RATE_LIMIT_ENABLED
        value: "true"
      - key: RATE_LIMIT_DEFAULT
        value: "200 per day, 50 per hour"

  # Celery Worker Service for AI Processing
  - name: celery-worker
    source_dir: /
    github:
      repo: mikebelloli/dojo-flask
      branch: main
      deploy_on_push: true
    dockerfile_path: Dockerfile
    run_command: |
      celery -A backend.src.ai.celery_worker.celery worker --loglevel=info --concurrency=2 --max-tasks-per-child=10
    environment_slug: python
    instance_count: 1
    instance_size_slug: basic-s  # Larger for AI processing
    envs:
      # Core Configuration
      - key: FLASK_ENV
        value: production
      - key: DATABASE_URL
        value: ${postgres-db.DATABASE_URL}
      - key: REDIS_URL
        value: ${redis-db.DATABASE_URL}
      
      # File Storage
      - key: MODEL_CACHE_DIR
        value: /app/models
      - key: UPLOAD_FOLDER
        value: /app/storage/uploads
      - key: PROCESSED_FOLDER
        value: /app/storage/processed
      
      # AI Configuration
      - key: WHISPER_MODEL
        value: base
      - key: LLM_MODEL
        value: microsoft/DialoGPT-medium
      - key: USE_GPU
        value: "false"
      - key: DEVICE
        value: cpu
      
      # Spaces Configuration
      - key: DO_SPACES_ENDPOINT
        value: ${DO_SPACES_ENDPOINT}
        type: SECRET
      - key: DO_SPACES_BUCKET
        value: ${DO_SPACES_BUCKET}
        type: SECRET
      - key: DO_SPACES_ACCESS_KEY
        value: ${DO_SPACES_ACCESS_KEY}
        type: SECRET
      - key: DO_SPACES_SECRET_KEY
        value: ${DO_SPACES_SECRET_KEY}
        type: SECRET
      
      # Celery Configuration
      - key: CELERY_BROKER_URL
        value: ${redis-db.DATABASE_URL}
      - key: CELERY_RESULT_BACKEND
        value: ${redis-db.DATABASE_URL}
      
      # Logging
      - key: LOG_LEVEL
        value: INFO
      - key: SENTRY_DSN
        value: ${SENTRY_DSN}
        type: SECRET

  # Celery Monitoring (Flower) - Optional
  - name: celery-monitor
    source_dir: /
    github:
      repo: mikebelloli/dojo-flask
      branch: main
      deploy_on_push: true
    dockerfile_path: Dockerfile
    run_command: |
      celery -A backend.src.ai.celery_worker.celery flower --port=8080 --basic_auth=${FLOWER_USER}:${FLOWER_PASSWORD}
    environment_slug: python
    instance_count: 1
    instance_size_slug: basic-xxs
    http_port: 8080
    routes:
      - path: /flower
    envs:
      - key: REDIS_URL
        value: ${redis-db.DATABASE_URL}
      - key: CELERY_BROKER_URL
        value: ${redis-db.DATABASE_URL}
      - key: FLOWER_USER
        value: ${FLOWER_USER}
        type: SECRET
      - key: FLOWER_PASSWORD
        value: ${FLOWER_PASSWORD}
        type: SECRET

# Frontend Static Site
static_sites:
  - name: frontend
    source_dir: /
    github:
      repo: mikebelloli/dojo-flask
      branch: main
      deploy_on_push: true
    build_command: |
      echo "Building Next.js frontend for DigitalOcean..."
      npm ci --production=false
      npm run build
    output_dir: /.next
    environment_slug: node-js
    routes:
      - path: /
    error_document: /404.html
    cors:
      allow_origins:
        - exact: https://${backend-api.DOMAIN}
      allow_methods:
        - GET
        - POST
        - PUT
        - DELETE
        - OPTIONS
      allow_headers:
        - Content-Type
        - Authorization
        - X-Requested-With
    envs:
      # Frontend Configuration
      - key: NODE_ENV
        value: production
      - key: NEXT_PUBLIC_API_URL
        value: https://${backend-api.DOMAIN}
      - key: NEXT_PUBLIC_WS_URL
        value: wss://${backend-api.DOMAIN}
      
      # Build Configuration
      - key: NEXT_TELEMETRY_DISABLED
        value: "1"
      - key: NPM_CONFIG_PRODUCTION
        value: "false"

# Jobs for maintenance tasks
jobs:
  - name: db-migrate
    source_dir: /
    github:
      repo: mikebelloli/dojo-flask
      branch: main
    dockerfile_path: Dockerfile
    run_command: python -m flask db upgrade
    environment_slug: python
    instance_count: 1
    instance_size_slug: basic-xxs
    kind: PRE_DEPLOY
    envs:
      - key: DATABASE_URL
        value: ${postgres-db.DATABASE_URL}
      - key: FLASK_ENV
        value: production

  - name: model-preload
    source_dir: /
    github:
      repo: mikebelloli/dojo-flask  
      branch: main
    dockerfile_path: Dockerfile
    run_command: python -c "from backend.src.ai.model_manager import ModelManager; ModelManager().preload_models()"
    environment_slug: python
    instance_count: 1
    instance_size_slug: basic-s
    kind: POST_DEPLOY
    envs:
      - key: MODEL_CACHE_DIR
        value: /app/models
      - key: WHISPER_MODEL
        value: base
      - key: LLM_MODEL
        value: microsoft/DialoGPT-medium 