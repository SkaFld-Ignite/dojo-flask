version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-video_chaptering}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - app-network

  # Redis for job queuing and caching
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 3s
      retries: 3
    networks:
      - app-network

  # MinIO (S3-compatible storage) to simulate DigitalOcean Spaces
  minio:
    image: minio/minio:latest
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY:-minioadmin123}
    ports:
      - "9000:9000"
      - "9001:9001"  # Console
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - app-network

  # Flask Backend API
  backend-api:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      # Core Flask Configuration
      - FLASK_ENV=${FLASK_ENV:-production}
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-video_chaptering}
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-change-in-production}
      
      # CORS Configuration
      - CORS_ORIGINS=http://localhost:3000,http://frontend:3000
      
      # File Storage
      - MODEL_CACHE_DIR=/app/models
      - UPLOAD_FOLDER=/app/storage/uploads
      - PROCESSED_FOLDER=/app/storage/processed
      - MAX_CONTENT_LENGTH=500MB
      
      # AI Configuration
      - WHISPER_MODEL=base
      - LLM_MODEL=microsoft/DialoGPT-medium
      - USE_GPU=false
      - DEVICE=cpu
      
      # MinIO/Spaces Configuration
      - DO_SPACES_ENDPOINT=http://minio:9000
      - DO_SPACES_BUCKET=ai-video-chaptering
      - DO_SPACES_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - DO_SPACES_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin123}
      - DO_SPACES_REGION=us-east-1
      
      # Celery Configuration
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # WebSocket Configuration
      - SOCKETIO_ASYNC_MODE=eventlet
      - SOCKETIO_CORS_ALLOWED_ORIGINS=*
      
      # Logging
      - LOG_LEVEL=INFO
      - LOG_FILE=/app/logs/app.log
    ports:
      - "8000:8000"
    volumes:
      - ./storage:/app/storage
      - ./models:/app/models
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - app-network

  # Celery Worker for AI Processing
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    command: celery -A backend.src.ai.celery_worker.celery worker --loglevel=info --concurrency=2 --max-tasks-per-child=10
    environment:
      # Core Configuration
      - FLASK_ENV=${FLASK_ENV:-production}
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-video_chaptering}
      - REDIS_URL=redis://redis:6379/0
      
      # File Storage
      - MODEL_CACHE_DIR=/app/models
      - UPLOAD_FOLDER=/app/storage/uploads
      - PROCESSED_FOLDER=/app/storage/processed
      
      # AI Configuration
      - WHISPER_MODEL=base
      - LLM_MODEL=microsoft/DialoGPT-medium
      - USE_GPU=false
      - DEVICE=cpu
      
      # MinIO Configuration
      - DO_SPACES_ENDPOINT=http://minio:9000
      - DO_SPACES_BUCKET=ai-video-chaptering
      - DO_SPACES_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - DO_SPACES_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin123}
      
      # Celery Configuration
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # Logging
      - LOG_LEVEL=INFO
    volumes:
      - ./storage:/app/storage
      - ./models:/app/models
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend-api:
        condition: service_healthy
    networks:
      - app-network

  # Celery Monitoring (Flower)
  celery-monitor:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    command: celery -A backend.src.ai.celery_worker.celery flower --port=5555 --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin123}
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_USER=${FLOWER_USER:-admin}
      - FLOWER_PASSWORD=${FLOWER_PASSWORD:-admin123}
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - celery-worker
    networks:
      - app-network

  # Next.js Frontend
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
      args:
        - NEXT_PUBLIC_API_URL=http://localhost:8000
        - NEXT_PUBLIC_WS_URL=ws://localhost:8000
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://backend-api:8000
      - NEXT_PUBLIC_WS_URL=ws://backend-api:8000
      - NEXT_TELEMETRY_DISABLED=1
    ports:
      - "3000:3000"
    depends_on:
      backend-api:
        condition: service_healthy
    networks:
      - app-network

  # Nginx Load Balancer/Reverse Proxy
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./nginx/ssl:/etc/nginx/ssl  # For SSL certificates
    depends_on:
      - frontend
      - backend-api
    networks:
      - app-network

  # Database backup service
  db-backup:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      - PGPASSWORD=${POSTGRES_PASSWORD:-postgres}
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh
    command: |
      sh -c "
        while true; do
          sleep 86400  # 24 hours
          pg_dump -h postgres -U ${POSTGRES_USER:-postgres} ${POSTGRES_DB:-video_chaptering} > /backups/backup_$(date +%Y%m%d_%H%M%S).sql
          find /backups -name 'backup_*.sql' -mtime +7 -delete  # Keep backups for 7 days
        done
      "
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - app-network

volumes:
  postgres_data:
  redis_data:
  minio_data:

networks:
  app-network:
    driver: bridge 